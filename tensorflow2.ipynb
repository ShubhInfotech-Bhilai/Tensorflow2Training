{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uePIrjqGAJDw",
        "colab_type": "text"
      },
      "source": [
        "# Topic 1 Overview of Machine Learning and Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTJ9sP3Yv1kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0 --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeTTuPEjwGcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Bl6QjNwmS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GISVAwjU9PU-",
        "colab_type": "text"
      },
      "source": [
        "# Topic 2 Basic Tensorflow Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS9iF4AwcWKt",
        "colab_type": "text"
      },
      "source": [
        "## Tensor and Constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLBI18if63u9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant(4,dtype=tf.float32)\n",
        "b = tf.constant(5.6,dtype=tf.float32)\n",
        "print(a*b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Do6TJkdxNPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant(4)\n",
        "b = tf.constant(5.6)\n",
        "print(a*b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHQ9avIY7dZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant([[1,2],[3,4]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeWF3s3u7lvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.transpose(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7BmWKDNTudj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant([1,5])\n",
        "a.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU306MXBcZQU",
        "colab_type": "text"
      },
      "source": [
        "## Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPyZfW0ZYpV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.Variable(0.0)\n",
        "a.assign_add(1)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOSyztU1ccDh",
        "colab_type": "text"
      },
      "source": [
        "## Gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwXAmGocTydw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "  return x*x*x\n",
        "\n",
        "x = tf.Variable(2.0)\n",
        "# x = tf.constant(2)\n",
        "\n",
        "with tf.GradientTape() as g:   \n",
        " y = f(x)\n",
        "dy_dx = g.gradient(y,x)\n",
        "dy_dx.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ntk8k09ceLy",
        "colab_type": "text"
      },
      "source": [
        "## Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIag4x_q7vtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant([[1,2],[3,4]])\n",
        "b = tf.constant([[5,6],[7,8]])\n",
        "tf.matmul(a,b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLYPxjCcP2P",
        "colab_type": "text"
      },
      "source": [
        "## Exercise: Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pem37r1W8rqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant([[1.1,1.2]],dtype=tf.float32)\n",
        "w = tf.constant([[1,2],[3,4]],dtype=tf.float32)\n",
        "b = tf.constant([[2.3,2.5]],dtype=tf.float32)\n",
        "y = tf.matmul(x,w)+b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta0n4LpecmZb",
        "colab_type": "text"
      },
      "source": [
        "## Graph Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP2L0o7cTozu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  return x*x*x\n",
        "\n",
        "x = tf.Variable(2.0)\n",
        "\n",
        "with tf.GradientTape() as g:  \n",
        " y = f(x)\n",
        "dy_dx = g.gradient(y,x)\n",
        "dy_dx.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLBinrnQBUaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def matmul_graph(a,b):\n",
        "    return tf.matmul(a,b)\n",
        "\n",
        "a = tf.constant([[1,2],[3,4]])\n",
        "b = tf.constant([[5,6],[7,8]])\n",
        "matmul_eager(a,b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS9IJlJaMaT7",
        "colab_type": "text"
      },
      "source": [
        "# Topic 3 Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE7Rj815AXks",
        "colab_type": "text"
      },
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDLY4X1_1P5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH2fG4SuFlh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIJa7-5FsuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(y_train[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eFpPIeZAabY",
        "colab_type": "text"
      },
      "source": [
        "## Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF3AKWVcHiQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ofmYg-FupD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9cXEWr9HuXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxDTlmbiHx7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N49NrPlcAddg",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-rlfCm-I4AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE0eKCG8Fzic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap22osu2KY4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXILK8u9Jbdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(class_names[y_train[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoC6dbd2bRKA",
        "colab_type": "text"
      },
      "source": [
        "## IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9wjPq4lbUOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKgjQ1Cp3ck2",
        "colab_type": "text"
      },
      "source": [
        "# Topic 4 Neural Networks for Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1WP-Y6cTHOJ",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NklScv9T4Qin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4jud2JtHeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEnw4DOK4paU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.7,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyf4b2peeaIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('medv')\n",
        "test_labels = test_dataset.pop('medv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9p5Xxxr7OUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcMoUt5651S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYHoIlOnTOIx",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0icWR2jozrFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbOpuGY8zzZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu',input_shape=[len(train_dataset.keys())]))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nT2BAqZ1bgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui4mp-xbQnch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sQQ0-OwJGV5",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfWmmre_Gxvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, 'my_first_model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_JTBz0UG7Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Q-M1B6TUoS",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaEA22PM7u-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(normed_train_data, train_labels,epochs=EPOCHS,shuffle=True, validation_data=(normed_test_data,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNHRRuO5Taiu",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHuFHb-u1u1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "epoch = range(len(mae))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,mae,label='mae')\n",
        "plt.plot(epoch,val_mae,label='val_mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error [MPG]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eiSHvsoS75G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "print(\"Testing Mean Abs Error: {:5.2f}\".format(mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0t-WVkCUb6S",
        "colab_type": "text"
      },
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WGbmq8Txjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hi9pgiAb_Wc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### Save the Model in HDF5 Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIn_PdWVYWUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"regression.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0_-g09jL-S",
        "colab_type": "text"
      },
      "source": [
        "### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqTRRcZPv8WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = keras.models.load_model('regression.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbl5w8vDjTwU",
        "colab_type": "text"
      },
      "source": [
        "### Save the Model in SavedModel Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8THLTbmwGa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"regression/1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRIuYbSdwoUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = keras.models.load_model('regression/1/')\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfhIrE2fDRDv",
        "colab_type": "text"
      },
      "source": [
        "### Save and Load Weighta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhivcJ8DDXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./regression/1/w')\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('./regression/1/w)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VgV9NCaZxUb",
        "colab_type": "text"
      },
      "source": [
        "### Exercise: Predictive Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i576kB-VZwft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv\"\n",
        "                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j5Bikh8aUVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.pop('Name')\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxJQ5K88agh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xTPXgMaauPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('SepalWidth')\n",
        "test_labels = test_dataset.pop('SepalWidth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_IJ8nckaiFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrKWvf9Wa2kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaT3T4R5a79X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSDblFbWa_rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu',input_shape=[len(train_dataset.keys())]))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFFp6-9EbMj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JATAjHErbRNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja3XlvETbGDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(normed_train_data, train_labels,epochs=EPOCHS,shuffle=True, validation_data=(normed_test_data,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkUA2yabWRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "epoch = range(len(mae))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,mae,label='mae')\n",
        "plt.plot(epoch,val_mae,label='val_mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error [MPG]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7xuGFMbfXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "print(\"Testing Mean Abs Error: {:5.2f}\".format(mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSqoBm8bkIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [Sepal Width]')\n",
        "plt.ylabel('Predictions [Sepal Width]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-600, 600], [-600, 600])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV5IJg197lM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"iris.h5\")\n",
        "\n",
        "# tf.saved_model.save(model, \"/model_iris/1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhx2FdHzubCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = keras.models.load_model('iris.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfphVHCuhmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kFBAGkA97hH",
        "colab_type": "text"
      },
      "source": [
        "# Topic 5 Neural Network for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuR1qtSVAu1a",
        "colab_type": "text"
      },
      "source": [
        "## NN Demo on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtyZurvwcbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V0RpO3tw000",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D41u9e5ZykId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFfmbYnE7gpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Fe_T99zIWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQI2tECjzkvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWe-1joB0A-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKFgWbY_7Px0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVDPhv-7op-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"mnist.h5\")\n",
        "\n",
        "# tf.saved_model.save(model, \"/model_mnist/1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcuaHhkt7c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model =keras.models.load_model('mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mud-twRruHwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZOBUJ02-rA9",
        "colab_type": "text"
      },
      "source": [
        "### Ex: Classification for Fashsion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwcNE9URCjSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgrzqfvCrFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVFlrswCvds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epAIFevbCzCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inRenTUC2Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_8D8ooDYeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tEK_zvGDb9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGRt60Z5Deqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLGfwYKYDggP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save(\"classifcation_model_fashion_mnist.h5\")\n",
        "\n",
        "tf.saved_model.save(model, \"/model_fashion_mnist/1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr7i2L08IIp5",
        "colab_type": "text"
      },
      "source": [
        "# Topic 6 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvnz7eV2A8LN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOAh91fYFIii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndIDOO30NRkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PumM6VQbBKYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(28, 28,1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9s56hLvCyi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haowsN8SB5gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlKtXNM2g3fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2aSUHUah_m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wEuxiX_j56O",
        "colab_type": "text"
      },
      "source": [
        "## Ex: CNN on CIFAR dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN_Ku2X91WlQ",
        "colab_type": "text"
      },
      "source": [
        "### Import and Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkcKtFik0guh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYdyIB5_FENe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPXFAwUl1b5V",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7ApD3saz-4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKwQJWPG0CB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgQGI9_41fSJ",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcEp0NcN0RBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY6tbfDe1j3k",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3dRs4J6jNMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlJ9Xvoa1D-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb",
        "colab_type": "text"
      },
      "source": [
        "## Small Dataset: Cats and Dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3qK9B4liVT",
        "colab_type": "text"
      },
      "source": [
        "### Import the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVgi54-2gk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i02EGsya2lEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HtDXZUW2tpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50UcL1Cw2tlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwsapX6j22ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpIw2V0lmGF",
        "colab_type": "text"
      },
      "source": [
        "### Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQqwvi4270h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtOhb7kR3AC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0uVoHIQ3DbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3WCmo2nB-Q",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the raw images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMONiajb3N-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpOtG-O3P-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkKcszhEm-KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1vHLHUmUId",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7r_aTsV3TMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCS7L2amtYn",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG2URME73ePz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av71E0Qcnwon",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY2A6qRw3hee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkEPDE4CrSsf",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAALUD0-rmfJ",
        "colab_type": "text"
      },
      "source": [
        "#### Flipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQyFpPyD3haA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu86mPQO3yDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccQ-PHze30HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xffOmUy32B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-use the same custom plotting function defined and used\n",
        "# above to visualize the training images\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbWPTnTarthk",
        "colab_type": "text"
      },
      "source": [
        "#### Rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QltWM5Tl39FD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiAxHpDx39yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxBavO0o3_m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itVuzyJZrzVR",
        "colab_type": "text"
      },
      "source": [
        "#### Zoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkMC0CoJ4Bwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7WuP6qZy5R1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "713vYmsB4HaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2cdcwLT4Ieq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mpaNGixeDu",
        "colab_type": "text"
      },
      "source": [
        "### Applying Data Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkyUlE-g4KN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBNK6kzB4Nrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSY-00oU4SCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0_cFKmb4T8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aztdvJ9S4Vm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QU9CT1u4WYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu',  input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZu27Lx7yqPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWN9-NfR4Z5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXoQV63m4cQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk",
        "colab_type": "text"
      },
      "source": [
        "### Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVpfC2X4erj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlwee1LY0CA",
        "colab_type": "text"
      },
      "source": [
        "# Topic 7 Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftG5ka_YMyS",
        "colab_type": "text"
      },
      "source": [
        "## Text Classifcaiton With RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmqPrAWa75W",
        "colab_type": "text"
      },
      "source": [
        "### Load the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6eJ1XvJYREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZ-97-pcFIW",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s62nbYQoY5Bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow. keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm-q7PEUcqbM",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8MPZorXZFhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYXl4jvCZH-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size,epochs=15,validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTcnxwuMdWST",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BKGm4fumhlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "score, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwp6F2TQZNN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(15)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeWq_7zY6oh",
        "colab_type": "text"
      },
      "source": [
        "# Topic 8 Transfer Learning & Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22VeyXPY-8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIk0CekhlsHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMG-n_jLlvIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=(224,224,3))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUVxJm8l2jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "\n",
        "grace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
        "grace_hopper = Image.open(grace_hopper).resize((224,224))\n",
        "grace_hopper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSl-wurl_qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grace_hopper = np.array(grace_hopper)/255.0\n",
        "grace_hopper.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IUdLD3qmDN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = classifier.predict(grace_hopper[np.newaxis, ...])\n",
        "result.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5aXZwDOmJ_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class = np.argmax(result[0], axis=-1)\n",
        "predicted_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6dcirZmNUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aKz3mPpmRj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(grace_hopper)\n",
        "plt.axis('off')\n",
        "predicted_class_name = imagenet_labels[predicted_class]\n",
        "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3CuZLkJYJFO",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlvAk4VUcXD_",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR2Cd6aBYNol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTdLyezAYPZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPLIT_WEIGHTS = (8, 1, 1)\n",
        "splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\n",
        "\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs', split=list(splits),\n",
        "    with_info=True, as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89LQMlTbYkmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "get_label_name = metadata.features['label'].int2str\n",
        "\n",
        "for image, label in raw_train.take(2):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEs7BtZrcw3I",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJUIUxijY9Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 160 # All images will be resized to 160x160 and scale to [-1,1]\n",
        "\n",
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jaUJY1ZQEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = raw_train.map(format_example)\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1_s6wUFZSxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjDQr3dzZYDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnMFWTb7aebi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "   pass\n",
        "\n",
        "image_batch.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2bNzkykdDmT",
        "colab_type": "text"
      },
      "source": [
        "### Load the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PvcC5sVZdof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxD3zRQWaUSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_batch = base_model(image_batch)\n",
        "#print(feature_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYF0iAP4dUDE",
        "colab_type": "text"
      },
      "source": [
        "### Freeze the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or9BfZ06ZxIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrfj5a5aZ1Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86tMav0djFk",
        "colab_type": "text"
      },
      "source": [
        "### Flatten the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihIrX71daK5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFCAvT79dric",
        "colab_type": "text"
      },
      "source": [
        "### Add the classifer layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aSUaWTcawtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_layer = keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NynHYPjdd2Cn",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX4-O01Fazzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVhgi6Z-bA0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQQtkYV0d-Uy",
        "colab_type": "text"
      },
      "source": [
        "### Train the classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmcyNYkxa5Cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocEB8PnhbW1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train, num_val, num_test = (\n",
        "  metadata.splits['train'].num_examples*weight/10\n",
        "  for weight in SPLIT_WEIGHTS\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPPVPJObX-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10\n",
        "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
        "validation_steps = 20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3MNB6Zlbg_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sr4segcbiIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPmdN78veyk5",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcxrjsVoe01L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNH24fI-e_1a",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PvHloKGfPOE",
        "colab_type": "text"
      },
      "source": [
        "### Un-freeze the top layers of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ7UgXsUfCMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb-se3awfEug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTbYAInafQ6Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP-9hvPXgtHO",
        "colab_type": "text"
      },
      "source": [
        "## Text Classifcaiton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IRtP56pfjws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\")\n",
        "embeddings = embed([\"cat is on the mat\", \"dog is in the fog\"])\n",
        "embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV0NbyPygw_8",
        "colab_type": "text"
      },
      "source": [
        "#### Import IMBD data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBmP0OFwZpGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
        "\n",
        "(train_data, validation_data), test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=(train_validation_split, tfds.Split.TEST),\n",
        "    as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEe_0a0kZ3gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
        "train_examples_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hHWg25fabM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1WVLpakg4UG",
        "colab_type": "text"
      },
      "source": [
        "#### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYSD885paerj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
        "# hub_layer(train_examples_batch[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPOH4bKgaxnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCgUFUtVhPvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeN8yozYYd2d",
        "colab_type": "text"
      },
      "source": [
        "#### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffOynTfma2_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXAMKbAybIkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),epochs=20, validation_data=validation_data.batch(512),verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4IXMJpnYmZK",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaZLRUkQbQTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKw-43EEcPcj",
        "colab_type": "text"
      },
      "source": [
        "## OverFitting & UnderFitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hdSqFFaeb2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "NUM_WORDS = 10000\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "def multi_hot_sequences(sequences, dimension):\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, word_indices in enumerate(sequences):\n",
        "        results[i, word_indices] = 1.0  # set specific indices of results[i] to 1s\n",
        "    return results\n",
        "\n",
        "\n",
        "train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\n",
        "test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKN4H6sjcgus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline_model = keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "    keras.layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy', 'binary_crossentropy'])\n",
        "\n",
        "baseline_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsmlmun7cjsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline_history = baseline_model.fit(train_data,\n",
        "                                      train_labels,\n",
        "                                      epochs=20,\n",
        "                                      batch_size=512,\n",
        "                                      validation_data=(test_data, test_labels),\n",
        "                                      verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB61CWm-cnUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smaller_model = keras.Sequential([\n",
        "    keras.layers.Dense(4, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "    keras.layers.Dense(4, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "smaller_model.compile(optimizer='adam',\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy', 'binary_crossentropy'])\n",
        "\n",
        "smaller_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C20bLGmle5Zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smaller_history = smaller_model.fit(train_data,\n",
        "                                    train_labels,\n",
        "                                    epochs=20,\n",
        "                                    batch_size=512,\n",
        "                                    validation_data=(test_data, test_labels),\n",
        "                                    verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMY0lB4PfpPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigger_model = keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "bigger_model.compile(optimizer='adam',\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy','binary_crossentropy'])\n",
        "\n",
        "bigger_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JZ5AOJUftet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigger_history = bigger_model.fit(train_data, train_labels,\n",
        "                                  epochs=20,\n",
        "                                  batch_size=512,\n",
        "                                  validation_data=(test_data, test_labels),\n",
        "                                  verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0QIytZlrFBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "  plt.figure(figsize=(16,10))\n",
        "\n",
        "  for name, history in histories:\n",
        "    val = plt.plot(history.epoch, history.history['val_'+key],\n",
        "                   '--', label=name.title()+' Val')\n",
        "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
        "             label=name.title()+' Train')\n",
        "\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(key.replace('_',' ').title())\n",
        "  plt.legend()\n",
        "\n",
        "  plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "\n",
        "plot_history([('baseline', baseline_history),\n",
        "              ('smaller', smaller_history),\n",
        "              ('bigger', bigger_history)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTBglq_Qr4Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l2_model = keras.models.Sequential([\n",
        "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
        "                       activation='relu', input_shape=(NUM_WORDS,)),\n",
        "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
        "                       activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "l2_model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['accuracy', 'binary_crossentropy'])\n",
        "\n",
        "l2_model_history = l2_model.fit(train_data, train_labels,\n",
        "                                epochs=20,\n",
        "                                batch_size=512,\n",
        "                                validation_data=(test_data, test_labels),\n",
        "                                verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMawqWZ8szFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history([('baseline', baseline_history),\n",
        "              ('l2', l2_model_history)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-_4BUEmtH41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dpt_model = keras.models.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "dpt_model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy','binary_crossentropy'])\n",
        "\n",
        "dpt_model_history = dpt_model.fit(train_data, train_labels,\n",
        "                                  epochs=20,\n",
        "                                  batch_size=512,\n",
        "                                  validation_data=(test_data, test_labels),\n",
        "                                  verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuhOMpfitQfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history([('baseline', baseline_history),\n",
        "              ('dropout', dpt_model_history)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8M-eZxlU1Ql",
        "colab_type": "text"
      },
      "source": [
        "# (Optional) Topic 9 Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa5s4rd3IpNy",
        "colab_type": "text"
      },
      "source": [
        "## Sequential Model as Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUAaCFgMI1BF",
        "colab_type": "text"
      },
      "source": [
        "### MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrNY6GDlGrOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTwwfxODzgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model():\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xu-UJ6WGZrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR_NW9NRI3-t",
        "colab_type": "text"
      },
      "source": [
        "### Fashion MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPG2wYABIeUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMoXxUYzImXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbAOV2fSHd0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdDpxaSUHPHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sH7Cj5WKqoI",
        "colab_type": "text"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "slskr_9aKosJ",
        "colab": {}
      },
      "source": [
        "def nn_model(lr):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.Adam(lr)\n",
        "    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTMXtfcKtML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "lr = [0.001,0.01,0.1]\n",
        "acc=[]\n",
        "for i in lr:\n",
        "    model = nn_model(i)\n",
        "    model.fit(x_train,y_train,verbose=0)\n",
        "    loss,accuracy = model.evaluate(x_test,y_test)\n",
        "    acc.append(accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOvs7A5KK50d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.semilogx(lr,acc)\n",
        "plt.semilogx(lr,acc,'o')\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KA37_sbJHx2",
        "colab_type": "text"
      },
      "source": [
        "## Layers as Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3WniIUU44L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name='img')\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cCrFyG_VQCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSFaihMIVk6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.RMSprop(),metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=5,validation_data=(x_test,y_test))\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', test_scores[0])\n",
        "print('Test accuracy:', test_scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubArRQLVZFQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')\n",
        "del model\n",
        "# Recreate the exact same model purely from the file:\n",
        "model = keras.models.load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrlPLfRA65Td",
        "colab_type": "text"
      },
      "source": [
        "###Ensembling with Nested Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKjxR7nr64Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "  inputs = keras.Input(shape=(128,))\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(inputs)\n",
        "  return keras.Model(inputs, outputs)\n",
        "\n",
        "model1 = get_model()\n",
        "model2 = get_model()\n",
        "model3 = get_model()\n",
        "\n",
        "inputs = keras.Input(shape=(128,))\n",
        "y1 = model1(inputs)\n",
        "y2 = model2(inputs)\n",
        "y3 = model3(inputs)\n",
        "outputs = layers.average([y1, y2, y3])\n",
        "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ureVFSbwIj3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(ensemble_model, 'model.png')\n",
        "# keras.utils.plot_model(model, 'model.png', show_shapes=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpKv4VWeZWuR",
        "colab_type": "text"
      },
      "source": [
        "### Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSeutphmZWDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers \n",
        "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
        "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aDe2yOJ_dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(autoencoder, 'model.png')\n",
        "# keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA4waja1-oM5",
        "colab_type": "text"
      },
      "source": [
        "### Toy Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WlidFV2-lW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
        "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "block_1_output = layers.MaxPooling2D(3)(x)\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "block_2_output = layers.add([x, block_1_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "block_3_output = layers.add([x, block_2_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu')(block_3_output)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name='toy_resnet')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2XVAkH-vGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, 'mini_resnet.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIWAMHB5-2iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=1,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSocWTHHAMxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JS9mnQOAyID",
        "colab_type": "text"
      },
      "source": [
        "### Multiple Inputs and Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbI8q4kcAd55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tags = 12  # Number of unique issue tags\n",
        "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
        "num_departments = 4  # Number of departments for predictions\n",
        "\n",
        "title_input = keras.Input(shape=(None,), name='title')  # Variable-length sequence of ints\n",
        "body_input = keras.Input(shape=(None,), name='body')  # Variable-length sequence of ints\n",
        "tags_input = keras.Input(shape=(num_tags,), name='tags')  # Binary vectors of size `num_tags`\n",
        "\n",
        "# Embed each word in the title into a 64-dimensional vector\n",
        "title_features = layers.Embedding(num_words, 64)(title_input)\n",
        "# Embed each word in the text into a 64-dimensional vector\n",
        "body_features = layers.Embedding(num_words, 64)(body_input)\n",
        "\n",
        "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
        "title_features = layers.LSTM(128)(title_features)\n",
        "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
        "body_features = layers.LSTM(32)(body_features)\n",
        "\n",
        "# Merge all available features into a single large vector via concatenation\n",
        "x = layers.concatenate([title_features, body_features, tags_input])\n",
        "\n",
        "# Stick a logistic regression for priority prediction on top of the features\n",
        "priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x)\n",
        "# Stick a department classifier on top of the features\n",
        "department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x)\n",
        "\n",
        "# Instantiate an end-to-end model predicting both priority and department\n",
        "model = keras.Model(inputs=[title_input, body_input, tags_input],\n",
        "                    outputs=[priority_pred, department_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u8nLBvYAgjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njdRT2vKMXjl",
        "colab_type": "text"
      },
      "source": [
        "## Ex: Funcational API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWWaseitMMrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
        "\n",
        "x = layers.Conv2D(32,(3,3), activation='relu',padding='same')(inputs)\n",
        "x = layers.Conv2D(64,(3,3), activation='relu',padding='same')(x)\n",
        "y1 = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "x = layers.Conv2D(16,(3,3), activation='relu',padding='same')(inputs)\n",
        "x = layers.Conv2D(32,(3,3), activation='relu',padding='same')(x)\n",
        "x = layers.Conv2D(64,(3,3), activation='relu',padding='same')(x)\n",
        "y2 = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "y3 = layers.concatenate([y1, y2])\n",
        "y4 = layers.Flatten()(y3)\n",
        "y5 = layers.Dense(128,activation='softmax')(y4)\n",
        "outputs = layers.Dense(10,activation='softmax')(y5)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name='dual_cnn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu4U1MieNOhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.utils.plot_model(model, 'model.png')\n",
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUsqhsi5VFhN",
        "colab_type": "text"
      },
      "source": [
        "# (Optional) Topic 10 TF.Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M6_rRCbVHfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakQg7RzVPip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFnqG3iNVZ4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEvvRYR5VheN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E3hkgT4VsI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VGIkDDIWCeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5v6-r9YWHgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AaTSrCnWNjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNlHlL_2WQt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "\n",
        "  # Reset the metrics for the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6kWWwmhWV8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}